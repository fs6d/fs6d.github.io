<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="FS6D: Few-Shot 6D Pose Estimation of Novel Objects."> 
  <meta name="keywords" content="6D Object Pose Estimation, Few-Shot Learning, Synthesis Dataset">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>FS6D: Few-Shot 6D Pose Estimation of Novel Objects.</title>

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-W7GG8BJ');</script>
  <!-- End Google Tag Manager -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W7GG8BJ"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">FS6D: Few-Shot 6D Pose Estimation of Novel Objects</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/ethnhe">Yisheng He</a><sup>1</sup>,</span>
            <span class="author-block">
              Yao Wang<sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=bzzBut4AAAAJ&hl=zh-CN&oi=ao">Haoqiang Fan</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://cqf.io/">Qifeng Chen</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="http://www.jiansun.org/">Jian Sun</a><sup>2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Hong Kong University of Science and Technology</span>
            <span class="author-block"><sup>2</sup>Megvii Technology</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>ShapeNet6D Data</span>
                  </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ethnhe/FS6D"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <center><img src="static/images/intro_pic.png" alt="Alternative Text" width=50% class="center"></center>
      <center>
        <p>
          Given a few RGBD views of a novel objects with pose labels,
          the few-shot pose estimation network aims to estimate 6D pose of that object in a novel query scene without extra training.
          No precise CAD models are required as well.
        </p>
      </center>
      <!-- <h2 class="subtitle has-text-centered">
      </h2> --> 
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            6D object pose estimation networks are limited in their capability to scale to large numbers of object instances
            due to the close-set assumption and their reliance on high-fidelity object CAD models. In this work, we study a 
            new open set problem; the few-shot 6D object poses estimation: estimating the 6D pose of an unknown object by a 
            few support views without extra training. To tackle the problem, we point out the importance of fully exploring 
            the appearance and geometric relationship between the given support views and query scene patches and propose a 
            dense prototypes matching framework by extracting and matching dense RGBD prototypes with transformers. Moreover,
            we show that the priors from diverse appearances and shapes are crucial to the generalization capability under the
            problem setting and thus propose a large-scale RGBD photorealistic dataset (ShapeNet6D) for network pre-training. 
            A simple and effective online texture blending approach is also introduced to eliminate the domain gap from the synthesis dataset,
            which enriches appearance diversity at a low cost. Finally, we discuss possible solutions to this problem and establish benchmarks
             on popular datasets to facilitate future research.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- ShapeNet6D. -->
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Dataset</h2>
          <p>
            We introduce a large-scale photorealistic dataset (ShapeNet6D) to empower the network's generalizability to novel objects. 
            Rendered RGBD images are labeled with instance semantic segmentation and 6D pose parameters.
          </p>
          <center>
            <img src="static/images/shapenet6d.png" alt="Alternative Text" width=95% class="center">
          </center>
        </div>
      </div>
    </div>
    <!--/ ShapeNet6D. -->

    <!-- FS6D-DPM -->
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Method</h2>
          <p>
            A Siamese full flow bidirectional fusion network extracts rich appearance
            and geometric features from the support view and the query scene patch, respectively. 
            They are then fed into self- and cross-attention modules to obtain dense 
            support prototypes and query features to explore correspondence for pose estimation.
          </p>
          <center>
            <img src="static/images/fs6d_DPM.png" alt="Alternative Text" width=100% class="center">
          </center>
        </div>
      </div>
    </div>
    <!--/ FS6D-DPM -->

    <!-- Visual Effect. -->
    <div class="columns is-centered">
      <div class="column">
        <h2 class="title is-3">Results</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>Our framework can genralize to novel objects unseeen during training.</p>
            <center><img src="static/images/cmp_res.png" alt="Alternative Text" width=100% class="center"></center>
          </div>
        </div>
      </div>
    </div>
    <!--/ Visual Effect. -->

    <!-- Benchmark. -->
    <div class="columns is-centered">
      <div class="column">
        <h2 class="title is-3">Benchmarks</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>We establish benchmarks for the problem on two popular datasets to facilitate future research.</p>
            <center><img src="static/images/benchmark.png" alt="Alternative Text" width=100% class="center"></center>
          </div>
        </div>
      </div>
    </div>
    <!--/ Benchmark. -->



  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{he2022fs6d,
  author    = {Yisheng, He and Yao, Wang and Haoqiang, Fan and Qifeng, Chen and Jian, Sun},
  title     = {FS6D: Few-Shot 6D Pose Estimation of Novel Objects},
  journal   = {CVPR},
  year      = {2022},
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <center>
            The website template was borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>
          </center>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
