<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="FS6D: Few-Shot 6D Pose Estimation of Novel Objects."> 
  <meta name="keywords" content="6D Object Pose Estimation, Few-Shot Learning, Synthesis Dataset">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>FS6D: Few-Shot 6D Pose Estimation of Novel Objects.</title>

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-W7GG8BJ');</script>
  <!-- End Google Tag Manager -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W7GG8BJ"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">FS6D: Few-Shot 6D Pose Estimation of Novel Objects</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/ethnhe">Yisheng He</a><sup>1</sup>,</span>
            <span class="author-block">
              Yao Wang<sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=bzzBut4AAAAJ&hl=zh-CN&oi=ao">Haoqiang Fan</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://cqf.io/">Qifeng Chen</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="http://www.jiansun.org/">Jian Sun</a><sup>2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Hong Kong University of Science and Technology</span>
            <span class="author-block"><sup>2</sup>Megvii Technology</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ethnhe/FS6D"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/intro.png" alt="Alternative Text">

<!--       <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2> -->
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            6D object pose estimation networks are limited in their capability to scale to large numbers
            of object instances due to the close-set assumption and their reliance on high-fidelity object CAD models.
            In this work, we study a new open set problem; the few-shot 6D object poses estimation: estimating the 6D
            pose of an unknown object by a few views of it without extra training. 
            To tackle the problem, we point out the importance of fully exploring the appearance and geometric relationship
            between the given samples and query scenes and propose a dense prototypes matching framework by extracting and
            matching dense RGBD prototypes with transformers. Moreover, we show that the priors from diverse appearances and 
            shapes are crucial to the generalization capability under the problem setting and thus propose a large-scale RGBD 
            photorealistic dataset (ShapeNet6D) for network pre-training. To further eliminate the domain gap, a simple and 
            effective online texture blending approach is also introduced, which further enriches the appearance diversity at a low cost. 
            Finally, we discuss possible solutions to this problem and establish benchmarks on popular datasets to facilitate future research. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{he2022fs6d,
  author    = {Yisheng, He and Yao, Wang and Haoqiang, Fan and Qifeng, Chen and Jian, Sun},
  title     = {FS6D: Few-Shot 6D Pose Estimation of Novel Objects},
  journal   = {CVPR},
  year      = {2022},
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
            The website template was borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies,</a>
            licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.

        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
